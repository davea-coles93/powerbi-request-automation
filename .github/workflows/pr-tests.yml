name: PR Tests - PowerBI Validation

on:
  pull_request:
    branches: [master, main]
    paths:
      - 'models/**'
      - 'backend/**'
      - 'scripts/**'
      - 'aas-validator/**'
      - '.github/workflows/**'

# OIDC permissions for Azure authentication
permissions:
  id-token: write
  contents: read
  pull-requests: write

env:
  # Azure Analysis Services configuration
  AZURE_AAS_SERVER: ${{ secrets.AZURE_AAS_SERVER }}
  AZURE_AAS_DATABASE: ${{ secrets.AZURE_AAS_DATABASE }}
  AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
  AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  AZURE_RESOURCE_GROUP: ${{ secrets.AZURE_RESOURCE_GROUP }}
  AZURE_AAS_SERVER_NAME: ${{ secrets.AZURE_AAS_SERVER_NAME }}

jobs:
  validate-changes:
    runs-on: ubuntu-latest
    name: Validate PowerBI Changes

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install dependencies
        working-directory: ./backend
        run: npm ci

      - name: Check modified models
        id: changed-models
        run: |
          echo "Checking for modified .pbix files..."
          CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }} | grep '\.pbix$' || true)
          echo "changed_files=$CHANGED_FILES" >> $GITHUB_OUTPUT
          if [ -n "$CHANGED_FILES" ]; then
            echo "Modified models:"
            echo "$CHANGED_FILES"
          else
            echo "No .pbix files modified"
          fi

      - name: Validate clients.json
        run: |
          echo "Validating clients.json structure..."
          node -e "
            const fs = require('fs');
            const config = JSON.parse(fs.readFileSync('models/clients.json', 'utf-8'));

            if (!config.clients || !Array.isArray(config.clients)) {
              throw new Error('clients.json must have a clients array');
            }

            for (const client of config.clients) {
              if (!client.id || !client.name || !Array.isArray(client.models)) {
                throw new Error('Each client must have id, name, and models array');
              }

              for (const model of client.models) {
                if (!model.id || !model.name || !model.file) {
                  throw new Error('Each model must have id, name, and file');
                }

                // Check if model file exists
                const modelPath = 'models/' + model.file;
                if (!fs.existsSync(modelPath)) {
                  console.warn('Warning: Model file not found: ' + modelPath);
                }
              }
            }

            console.log('‚úÖ clients.json validation passed');
            console.log('   Clients: ' + config.clients.length);
            console.log('   Total models: ' + config.clients.reduce((sum, c) => sum + c.models.length, 0));
          "

      - name: Extract PR info
        id: pr-info
        run: |
          # Write PR body to file to avoid shell escaping issues with DAX expressions
          cat > pr_body.txt << 'EOF'
          ${{ github.event.pull_request.body }}
          EOF

          # Extract request ID from PR body
          REQUEST_ID=$(grep -oP 'Request ID.*\`\K[^`]+' pr_body.txt || echo "unknown")
          echo "request_id=$REQUEST_ID" >> $GITHUB_OUTPUT

          # Extract client from PR body
          CLIENT=$(grep -oP 'Client.*\|\s*\K[^|]+' pr_body.txt | head -1 | xargs || echo "unknown")
          echo "client=$CLIENT" >> $GITHUB_OUTPUT

          # Extract model from PR body
          MODEL=$(grep -oP 'Model.*\|\s*\K[^|]+' pr_body.txt | head -1 | xargs || echo "unknown")
          echo "model=$MODEL" >> $GITHUB_OUTPUT

          # Cleanup
          rm -f pr_body.txt

          echo "Request ID: $REQUEST_ID"
          echo "Client: $CLIENT"
          echo "Model: $MODEL"

      - name: Post validation summary
        uses: actions/github-script@v7
        with:
          script: |
            const changedFiles = '${{ steps.changed-models.outputs.changed_files }}';
            const requestId = '${{ steps.pr-info.outputs.request_id }}';
            const client = '${{ steps.pr-info.outputs.client }}';
            const model = '${{ steps.pr-info.outputs.model }}';

            const body = `## üîç PR Validation Results

            ### Request Details
            | Field | Value |
            |-------|-------|
            | Request ID | \`${requestId}\` |
            | Client | ${client} |
            | Model | ${model} |

            ### Changed Files
            ${changedFiles ? changedFiles.split('\n').map(f => `- \`${f}\``).join('\n') : '_No .pbix files changed_'}

            ### Validation Status
            - ‚úÖ clients.json structure valid
            - ‚úÖ Model references valid

            ### Next Steps
            1. Download the .pbix file and open in PowerBI Desktop
            2. Verify the changes work as expected
            3. Approve the PR if everything looks good

            ---
            _Automated validation by GitHub Actions_`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  # Azure Analysis Services DAX validation (runs if AAS is configured)
  dax-validation:
    runs-on: ubuntu-latest
    name: DAX Validation (Azure Analysis Services)
    if: vars.ENABLE_AAS_VALIDATION == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '6.0.x'

      # OIDC Login to Azure
      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Build AAS Validator
        working-directory: ./aas-validator/AasValidator
        run: dotnet build -c Release

      - name: Start Azure Analysis Services
        id: start-aas
        run: |
          echo "Starting Azure Analysis Services (billing begins)..."
          # Get access token from Azure CLI (already authenticated via OIDC)
          ACCESS_TOKEN=$(az account get-access-token --resource https://management.azure.com/ --query accessToken -o tsv)

          # Use PowerShell Az.AnalysisServices
          pwsh -Command "
            \$Token = '$ACCESS_TOKEN'
            Install-Module -Name Az.AnalysisServices, Az.Accounts -Force -Scope CurrentUser -AllowClobber
            Connect-AzAccount -AccessToken \$Token -AccountId '${{ secrets.AZURE_CLIENT_ID }}' -Subscription '${{ secrets.AZURE_SUBSCRIPTION_ID }}'
            Resume-AzAnalysisServicesServer -Name '${{ secrets.AZURE_AAS_SERVER_NAME }}' -ResourceGroupName '${{ secrets.AZURE_RESOURCE_GROUP }}'
          "
          echo "Waiting for server to be ready..."
          sleep 30

      - name: Get Azure access token for AAS
        id: get-token
        run: |
          # Get token for Analysis Services
          TOKEN=$(az account get-access-token --resource "https://*.asazure.windows.net" --query accessToken -o tsv)
          echo "::add-mask::$TOKEN"
          echo "AAS_ACCESS_TOKEN=$TOKEN" >> $GITHUB_ENV

      - name: Install PowerShell SqlServer module
        run: |
          echo "Installing SqlServer PowerShell module for TMSL execution..."
          pwsh -Command "Install-Module -Name SqlServer -Force -Scope CurrentUser -AllowClobber"
          echo "‚úÖ SqlServer module installed"

      - name: Run TMDL syntax validation
        run: |
          echo "Running TMDL syntax validation (Option 1)..."
          node scripts/validate-tmdl.js models/adventure-works/sales-sample.SemanticModel

      - name: Deploy TMDL model to AAS for validation
        id: deploy-tmdl
        env:
          AAS_ACCESS_TOKEN: ${{ env.AAS_ACCESS_TOKEN }}
        run: |
          echo "Deploying TMDL model to AAS (Option 2)..."

          # Generate temporary database name
          DATABASE_NAME="tmdl-ci-$(date +%s)"
          echo "CI_DATABASE_NAME=$DATABASE_NAME" >> $GITHUB_ENV
          echo "Database name: $DATABASE_NAME"

          # Parse TMDL and generate TMSL
          node scripts/deploy-tmdl-model.js models/adventure-works/sales-sample.SemanticModel

          # Get the generated TMSL file (script outputs this path)
          TMSL_FILE="${DATABASE_NAME}.tmsl.json"
          if [ ! -f "scripts/$TMSL_FILE" ]; then
            echo "‚ùå TMSL file not found: scripts/$TMSL_FILE"
            exit 1
          fi

          # Deploy using PowerShell SqlServer module
          pwsh -Command "
            \$tmsl = Get-Content 'scripts/$TMSL_FILE' -Raw
            \$token = '$AAS_ACCESS_TOKEN'

            # Import SqlServer module
            Import-Module SqlServer

            # Execute TMSL
            try {
              Invoke-ASCmd -Query \$tmsl -Server '${{ secrets.AZURE_AAS_SERVER }}' -Credential (New-Object PSCredential('app', (ConvertTo-SecureString \$token -AsPlainText -Force)))
              Write-Output '‚úÖ TMDL model deployed successfully'
            } catch {
              Write-Error \"Deployment failed: \$_\"
              exit 1
            }
          "

      - name: Validate DAX measures against deployed model
        id: dax-tests
        env:
          AAS_ACCESS_TOKEN: ${{ env.AAS_ACCESS_TOKEN }}
        run: |
          echo "Validating DAX measures from TMDL model..."

          # Parse TMDL files to extract measures
          node -e "
            const fs = require('fs');
            const path = require('path');

            function extractMeasures(tmdlContent, filePath) {
              const measures = [];
              const lines = tmdlContent.split('\n');
              let currentMeasure = null;
              let inDaxBlock = false;
              let daxLines = [];

              for (let i = 0; i < lines.length; i++) {
                const line = lines[i];
                const measureMatch = line.match(/^\s*measure\s+(?:'([^']+)'|(\S+))\s*=\s*\`\`\`/);

                if (measureMatch) {
                  currentMeasure = measureMatch[1] || measureMatch[2];
                  inDaxBlock = true;
                  daxLines = [];
                  continue;
                }

                if (inDaxBlock && line.trim() === '\`\`\`') {
                  measures.push({ name: currentMeasure, dax: daxLines.join('\n').trim(), file: filePath });
                  currentMeasure = null;
                  inDaxBlock = false;
                  daxLines = [];
                  continue;
                }

                if (inDaxBlock) {
                  daxLines.push(line);
                }
              }

              return measures;
            }

            // Find all TMDL files
            const modelPath = 'models/adventure-works/sales-sample.SemanticModel';
            const tablesPath = path.join(modelPath, 'definition', 'tables');
            const files = fs.readdirSync(tablesPath).filter(f => f.endsWith('.tmdl'));

            let allMeasures = [];
            for (const file of files) {
              const content = fs.readFileSync(path.join(tablesPath, file), 'utf8');
              const measures = extractMeasures(content, file);
              allMeasures = allMeasures.concat(measures);
            }

            // Write measures to file for validation
            fs.writeFileSync('measures.json', JSON.stringify(allMeasures, null, 2));
            console.log(\`Found \${allMeasures.length} measures to validate\`);
          "

          # Validate each measure
          MEASURES=$(cat measures.json)
          MEASURE_COUNT=$(echo "$MEASURES" | jq length)

          echo "Validating $MEASURE_COUNT measures..."

          FAILED=0
          for i in $(seq 0 $(($MEASURE_COUNT - 1))); do
            MEASURE_NAME=$(echo "$MEASURES" | jq -r ".[$i].name")
            MEASURE_DAX=$(echo "$MEASURES" | jq -r ".[$i].dax")

            echo "  Validating: $MEASURE_NAME"

            cd aas-validator/AasValidator
            RESULT=$(dotnet run -- \
              --server "${{ secrets.AZURE_AAS_SERVER }}" \
              --database "$CI_DATABASE_NAME" \
              --token "$AAS_ACCESS_TOKEN" \
              --command validate \
              --query "$MEASURE_DAX" 2>&1 || true)
            cd ../..

            VALID=$(echo "$RESULT" | jq -r '.valid' 2>/dev/null || echo "false")

            if [ "$VALID" = "true" ]; then
              echo "    ‚úÖ Valid"
            else
              echo "    ‚ùå Invalid"
              ERROR=$(echo "$RESULT" | jq -r '.error' 2>/dev/null || echo "$RESULT")
              echo "    Error: $ERROR"
              FAILED=$((FAILED + 1))
            fi
          done

          if [ $FAILED -gt 0 ]; then
            echo ""
            echo "‚ùå $FAILED measure(s) failed validation"
            exit 1
          fi

          echo ""
          echo "‚úÖ All $MEASURE_COUNT measures validated successfully!"

      - name: Delete TMDL model from AAS
        if: always() && env.CI_DATABASE_NAME != ''
        env:
          AAS_ACCESS_TOKEN: ${{ env.AAS_ACCESS_TOKEN }}
        run: |
          if [ -n "$CI_DATABASE_NAME" ]; then
            echo "Deleting temporary TMDL model: $CI_DATABASE_NAME"

            # Delete using PowerShell TMSL
            pwsh -Command "
              \$token = '$AAS_ACCESS_TOKEN'
              \$tmsl = @\"
              {
                \"\"delete\"\": {
                  \"\"object\"\": {
                    \"\"database\"\": \"\"$CI_DATABASE_NAME\"\"
                  }
                }
              }
\"@

              Import-Module SqlServer
              try {
                Invoke-ASCmd -Query \$tmsl -Server '${{ secrets.AZURE_AAS_SERVER }}' -Credential (New-Object PSCredential('app', (ConvertTo-SecureString \$token -AsPlainText -Force)))
                Write-Output '‚úÖ TMDL model deleted'
              } catch {
                Write-Warning \"Database cleanup failed: \$_\"
              }
            "
          fi

      - name: Stop Azure Analysis Services
        if: always()
        run: |
          echo "Stopping Azure Analysis Services (billing stops)..."
          # Get access token and suspend AAS
          ACCESS_TOKEN=$(az account get-access-token --resource https://management.azure.com/ --query accessToken -o tsv) || true

          pwsh -Command "
            \$Token = '$ACCESS_TOKEN'
            Connect-AzAccount -AccessToken \$Token -AccountId '${{ secrets.AZURE_CLIENT_ID }}' -Subscription '${{ secrets.AZURE_SUBSCRIPTION_ID }}' -ErrorAction SilentlyContinue
            Suspend-AzAnalysisServicesServer -Name '${{ secrets.AZURE_AAS_SERVER_NAME }}' -ResourceGroupName '${{ secrets.AZURE_RESOURCE_GROUP }}' -ErrorAction SilentlyContinue
          " || true

      - name: Azure Logout
        if: always()
        run: az logout || true

      - name: Post DAX validation results
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const testResult = '${{ steps.dax-tests.outcome }}';
            const emoji = testResult === 'success' ? '‚úÖ' : '‚ùå';

            const body = `## üß™ DAX Validation Results

            | Test | Status |
            |------|--------|
            | AAS Connectivity | ${emoji} |
            | Model Info | ${emoji} |
            | Measure Listing | ${emoji} |
            | DAX Expression Validation | ${emoji} |

            **Overall Result:** ${testResult === 'success' ? '‚úÖ All tests passed' : '‚ùå Some tests failed'}

            ---
            _Validated against Azure Analysis Services_`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  notify-success:
    runs-on: ubuntu-latest
    needs: [validate-changes]
    if: success()

    steps:
      - name: Mark checks as passed
        run: |
          echo "‚úÖ All validations passed!"
          echo "The PR is ready for manual review."
